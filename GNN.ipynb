{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXC2QpTkCTX7",
        "outputId": "b13cd492-41d1-4959-bb69-83780ea1622d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch has version 2.3.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaXVivpWCULd",
        "outputId": "a25ee7f6-6a1b-40a8-9582-f486c9547b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m753.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/pyg_lib-0.4.0%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt23cu121 torch_cluster-1.6.3+pt23cu121 torch_scatter-2.1.2+pt23cu121 torch_sparse-0.6.18+pt23cu121 torch_spline_conv-1.2.2+pt23cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "# Optional dependencies:\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqdamXNsCKa8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MessagePassing, radius_graph\n",
        "import enum\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torch_scatter\n",
        "from torch_geometric.utils import to_networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr-dYCyXwtM3"
      },
      "outputs": [],
      "source": [
        "# Start seed\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgzOYlERCKa-"
      },
      "source": [
        "# Graph construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq0tOrbZCu5R"
      },
      "outputs": [],
      "source": [
        "# Create folder called Data\n",
        "data_path = \"Data\"\n",
        "if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "# Create folder called Model\n",
        "model_path = \"Model\"\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_7vCusQCKa_"
      },
      "outputs": [],
      "source": [
        "# Acceleration data\n",
        "df = pd.read_csv(\"Data/Data4.csv\")\n",
        "time = df[\"0\"].values\n",
        "df.drop(columns=[\"0\"], inplace=True)\n",
        "\n",
        "# Coordinates data\n",
        "df_coord = np.array([[2.5, 30*i] for i in range(0, df.shape[1])])\n",
        "\n",
        "# Node type\n",
        "node_type = np.zeros(df_coord.shape[0])\n",
        "node_type[[-1,0]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Gz2FOvsUzgat",
        "outputId": "f3b63ae3-0f3f-4638-cf1e-53c199a1cbf8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Input acceleration\n",
        "freq1 = 1.75 # Freq1\n",
        "t01 = 1.8 # Time Shift\n",
        "t = time\n",
        "wave = -2*freq1**2*np.pi**2*np.exp(-freq1**2*np.pi**2*(t01 - t)**2)*(t01 - t)*(2*freq1**2*np.pi**2*t01**2 - 4*freq1**2*np.pi**2*t01*t + 2*freq1**2*np.pi**2*t**2 - 3)\n",
        "# Create acceleration array input\n",
        "input_acc = np.zeros_like(df.values)\n",
        "input_acc[:,0] = wave\n",
        "\n",
        "\n",
        "plt.plot(input_acc[:,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eubBvlk0CKbA",
        "outputId": "039f5043-9339-4551-c085-86131f5781ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done collecting data!\n",
            "Data saved!\n",
            "Output Location:  Data/Data4.pt\n"
          ]
        }
      ],
      "source": [
        "# Initialize the data_list\n",
        "data_list = []\n",
        "\n",
        "# Time step\n",
        "dt = 1e-4\n",
        "\n",
        "# Spacing\n",
        "dx = 30\n",
        "\n",
        "# Establish some data\n",
        "number_trajectories = 1\n",
        "number_ts = -1\n",
        "\n",
        "# Create file_path\n",
        "data_path = \"Data\"\n",
        "save_data = True\n",
        "\n",
        "for k in range(df.shape[0]):\n",
        "    if k == number_ts:\n",
        "        break\n",
        "\n",
        "    # Get acceleration\n",
        "    acceleration_target = torch.tensor(df.iloc[k].values, dtype=torch.float).unsqueeze(1)\n",
        "    acceleration_input = torch.tensor(input_acc[k], dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    # Get node type\n",
        "    node_type_input = torch.tensor(node_type, dtype=torch.float)\n",
        "\n",
        "    # Get edge_index\n",
        "    coordinates = torch.tensor(df_coord, dtype=torch.float)\n",
        "    edges_index = radius_graph(coordinates, r=1.1*dx, loop=False).squeeze(0).type(torch.long)\n",
        "\n",
        "    # Get edge_attr\n",
        "    u_i = coordinates[edges_index[0]]\n",
        "    u_j = coordinates[edges_index[1]]\n",
        "    u_ij = u_i - u_j\n",
        "    u_ij_norm = torch.norm(u_ij, p=2, dim=1, keepdim=True)\n",
        "    edge_attr = torch.cat([u_ij, u_ij_norm], dim=-1).type(torch.float)\n",
        "\n",
        "    # Store data\n",
        "    data_list.append(Data(x=acceleration_input, edge_index=edges_index,\n",
        "                          edge_attr=edge_attr, y=acceleration_target, node_type=node_type_input))\n",
        "\n",
        "print(\"Done collecting data!\")\n",
        "\n",
        "# Save\n",
        "if save_data:\n",
        "  torch.save(data_list, os.path.join(data_path, \"Data4.pt\"))\n",
        "  print(\"Data saved!\")\n",
        "  print(\"Output Location: \", os.path.join(data_path, \"Data4.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck1-TlsbCKbC"
      },
      "source": [
        "# Normalization\n",
        "Normalization is necessary for the features and output parameters to zero mean and unit variance in order to stabilize training. The method defined below, get_stats(), is run before training. It accepts the processed data_list, calculates the mean and standard deviation for the node features, edge features, and node outputs, and normalizes these using the calculated statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHGw1EN5CKbC"
      },
      "outputs": [],
      "source": [
        "def normalize(to_normalize,mean_vec,std_vec):\n",
        "    return (to_normalize-mean_vec)/std_vec\n",
        "\n",
        "def unnormalize(to_unnormalize,mean_vec,std_vec):\n",
        "    return to_unnormalize*std_vec+mean_vec\n",
        "\n",
        "def get_stats(data_list):\n",
        "    '''\n",
        "    Method for normalizing processed datasets. Given  the processed data_list,\n",
        "    calculates the mean and standard deviation for the node features, edge features,\n",
        "    and node outputs, and normalizes these using the calculated statistics.\n",
        "    '''\n",
        "\n",
        "    # Mean and std of the node features are calculated\n",
        "    mean_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
        "    std_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
        "\n",
        "    # Mean and std of the edge features are calculated\n",
        "    mean_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
        "    std_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
        "\n",
        "    # Mean and std of the output parameters are calculated\n",
        "    mean_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
        "    std_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
        "\n",
        "    # Define the maximum number of accumulations to perform such that we do\n",
        "    # not encounter memory issues\n",
        "    max_accumulations = 10**6\n",
        "\n",
        "    #Define a very small value for normalizing to\n",
        "    eps=torch.tensor(1e-8)\n",
        "\n",
        "    #Define counters used in normalization\n",
        "    num_accs_x = 0\n",
        "    num_accs_edge = 0\n",
        "    num_accs_y = 0\n",
        "\n",
        "    #Iterate through the data in the list to accumulate statistics\n",
        "    for dp in data_list:\n",
        "\n",
        "        # Add to the mean and std vectors for the node features\n",
        "        mean_vec_x+=torch.sum(dp.x,dim=0)\n",
        "        std_vec_x+=torch.sum(dp.x**2,dim=0)\n",
        "        num_accs_x+=dp.x.shape[0]\n",
        "\n",
        "        # Add to the mean and std vectors for the edge features\n",
        "        mean_vec_edge +=torch.sum(dp.edge_attr,dim=0)\n",
        "        std_vec_edge +=torch.sum(dp.edge_attr**2,dim=0)\n",
        "        num_accs_edge +=dp.edge_attr.shape[0]\n",
        "\n",
        "        # Add to the mean and std vectors for the node outputs\n",
        "        mean_vec_y+=torch.sum(dp.y,dim=0)\n",
        "        std_vec_y+=torch.sum(dp.y**2,dim=0)\n",
        "        num_accs_y+=dp.y.shape[0]\n",
        "\n",
        "        if(num_accs_x>max_accumulations or num_accs_edge>max_accumulations or num_accs_y>max_accumulations):\n",
        "            break\n",
        "\n",
        "    mean_vec_x = mean_vec_x/num_accs_x\n",
        "    std_vec_x = torch.maximum(torch.sqrt(std_vec_x/num_accs_x - mean_vec_x**2),eps)\n",
        "\n",
        "    mean_vec_x = torch.nan_to_num(mean_vec_x, nan=0.0)\n",
        "    std_vec_x = torch.nan_to_num(std_vec_x, nan=1.0)\n",
        "\n",
        "    mean_vec_edge = mean_vec_edge/num_accs_edge\n",
        "    std_vec_edge = torch.maximum(torch.sqrt(std_vec_edge/num_accs_edge - mean_vec_edge**2),eps)\n",
        "\n",
        "    mean_vec_edge = torch.nan_to_num(mean_vec_edge, nan=0.0)\n",
        "    std_vec_edge = torch.nan_to_num(std_vec_edge, nan=1.0)\n",
        "\n",
        "    mean_vec_y = mean_vec_y/num_accs_y\n",
        "    std_vec_y = torch.maximum(torch.sqrt(std_vec_y/num_accs_y - mean_vec_y**2),eps)\n",
        "\n",
        "    mean_vec_y = torch.nan_to_num(mean_vec_y, nan=0.0)\n",
        "    std_vec_y = torch.nan_to_num(std_vec_y, nan=1.0)\n",
        "\n",
        "    mean_std_list=[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y]\n",
        "\n",
        "    return mean_std_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY278oypCKbD"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4JXMfYbCKbD"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.node_encoder = Sequential(Linear(input_dim_node , hidden_dim),\n",
        "                                ReLU(),\n",
        "                                Linear(hidden_dim, hidden_dim),\n",
        "                                LayerNorm(hidden_dim))\n",
        "\n",
        "        self.edge_encoder = Sequential(Linear(input_dim_edge , hidden_dim),\n",
        "                                ReLU(),\n",
        "                                Linear(hidden_dim, hidden_dim),\n",
        "                                LayerNorm(hidden_dim))\n",
        "\n",
        "    def forward(self, x, edge_attr):\n",
        "        x = self.node_encoder(x)\n",
        "        edge_attr = self.edge_encoder(edge_attr)\n",
        "        return x, edge_attr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ianlOGCKbD"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uQJ9ZqKCKbE"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim_node):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.node_decoder = Sequential(Linear(hidden_dim, hidden_dim),\n",
        "                                ReLU(),\n",
        "                                Linear(hidden_dim, output_dim_node))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.node_decoder(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vph3XNl2CKbE"
      },
      "source": [
        "# GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LclM6pkXCKbE"
      },
      "outputs": [],
      "source": [
        "class MeshGraphNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim, output_dim, args, emb=False):\n",
        "        super(MeshGraphNet, self).__init__()\n",
        "\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(input_dim_node, input_dim_edge, hidden_dim)\n",
        "\n",
        "        # Processor\n",
        "        self.processor = nn.ModuleList()\n",
        "        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n",
        "\n",
        "        processor_layer=self.build_processor_model()\n",
        "        for _ in range(self.num_layers):\n",
        "            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(hidden_dim, output_dim)\n",
        "\n",
        "    def build_processor_model(self):\n",
        "        return ProcessorLayer\n",
        "\n",
        "    def forward(self,data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge):\n",
        "\n",
        "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
        "\n",
        "        # Normalize the input data\n",
        "        x = normalize(x,mean_vec_x,std_vec_x)\n",
        "        edge_attr = normalize(edge_attr,mean_vec_edge,std_vec_edge)\n",
        "\n",
        "        # Encoder\n",
        "        x, edge_attr = self.encoder(x, edge_attr)\n",
        "\n",
        "        # Processor\n",
        "        for i in range(self.num_layers):\n",
        "            x, edge_attr = self.processor[i](x, edge_index, edge_attr)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def loss(self, pred, inputs, mean_vec_y, std_vec_y):\n",
        "\n",
        "        # Normalize the output data\n",
        "        y = inputs.y\n",
        "        y = normalize(y,mean_vec_y,std_vec_y)\n",
        "\n",
        "        # Get node type\n",
        "        node_type = inputs.node_type\n",
        "\n",
        "        y = y[node_type==1]\n",
        "        pred = pred[node_type==1]\n",
        "\n",
        "        # Calculate the loss\n",
        "        error=torch.sum((y-pred)**2,axis=1)\n",
        "\n",
        "        # Calculate the sqrt loss\n",
        "        loss = torch.sqrt(torch.mean(error))\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JpFyJNYCKbE"
      },
      "source": [
        "# ProcessorLayer Class: Edge Message Passing, Aggregation, and Updating\n",
        "\n",
        "Now let's implement the processor, which overrides \"[MessagePassing](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html)\" base class. Following the prototype of the base class, we need to implement three main methods, namely message passing, aggregation, and updating. Also, two types of MLP layers, namely node MLP and edge MLP, are defined and used during the construction of processor, whose details will be given in the cell bellow.\n",
        "\n",
        "Essentailly, our processor class serves as the GNN layers composed of message passing, aggregation, and updating, updating information at each layer of the computational graph for each node. The message passing process can be described as:\n",
        "\n",
        "1.   **Message passing**\n",
        "\n",
        "Initiated by the propagate function, the message function most generally calculates messages, m, for edge u at layer l with function MSG given previous embeddings h_u:\n",
        "$$m_u^{(l)}=MSG^{(l)}(h_u^{(l-1)})$$\n",
        "\n",
        "Note that for MeshGraphNets, messages are calculated for edges and passed to nodes. This function thus takes edge embeddings and the adjacent node embeddings and concatenates them. These concatenated previous embeddings constitute h_u above. These are then put through an MLP (our MSG function) to give the final messages, m_u, which are passed to the aggregate function.\n",
        "\n",
        "2.   **Aggregation**\n",
        "\n",
        "Aggregation takes the updated edge embeddings and aggregates then over the connectivity matrix indexing using sum reduction. Most generally, we have:\n",
        "\n",
        "$$h_v^{(l)}=AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})$$\n",
        "\n",
        "For MeshGraphNets, aggregation (AGG) for node v is sum over the neighbor nodes. However, there is also an additional aggregation step: aggregating with the self embedding. This is done outside of the aggregation function, in the forward function after the return of propagate:\n",
        "\n",
        "$$h_v^{(l)}=\\{h_v^{(l-1)},AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})\\}$$\n",
        "\n",
        "3.   **Updating**\n",
        "\n",
        "The nodes embeddings are finally updated by passing $h_v^{(l)}$ through the node MLP with a skip connection. This is most generally written as:\n",
        "\n",
        "$$h_v^{(l)}=Processor(h_v^{(l)})$$\n",
        "\n",
        "Where for us the Processor is an MLP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR1FOQMJCKbE"
      },
      "outputs": [],
      "source": [
        "class ProcessorLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(ProcessorLayer, self).__init__(**kwargs)\n",
        "\n",
        "        # Note that the node and edge encoders both have the same hidden dimension\n",
        "        # size. This means that the input of the edge processor will always be\n",
        "        # three times the specified hidden dimension\n",
        "        # (input: adjacent node embeddings and self embeddings)\n",
        "        self.edge_mlp = Sequential(Linear(3* in_channels , out_channels),\n",
        "                                   ReLU(),\n",
        "                                   Linear( out_channels, out_channels),\n",
        "                                   LayerNorm(out_channels))\n",
        "\n",
        "        self.node_mlp = Sequential(Linear(2* in_channels , out_channels),\n",
        "                                   ReLU(),\n",
        "                                   Linear( out_channels, out_channels),\n",
        "                                   LayerNorm(out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.edge_mlp[0].reset_parameters()\n",
        "        self.edge_mlp[2].reset_parameters()\n",
        "\n",
        "        self.node_mlp[0].reset_parameters()\n",
        "        self.node_mlp[2].reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, size=None):\n",
        "\n",
        "        out, updated_edges = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size) # Out has the shape of [E, out_channels]\n",
        "        updated_nodes = torch.cat([x, out], dim=1) # Complete the aggregation through self-aggregation\n",
        "        updated_nodes = x + self.node_mlp(updated_nodes) # Residual connection\n",
        "\n",
        "        return updated_nodes, updated_edges\n",
        "\n",
        "    def message(self, x_i, x_j, edge_attr):\n",
        "\n",
        "        updated_edges = torch.cat([x_i, x_j, edge_attr], dim=1) # Shape of [E, 3*in_channels]\n",
        "        updated_edges = self.edge_mlp(updated_edges)\n",
        "\n",
        "        return updated_edges\n",
        "\n",
        "    def aggregate(self, updated_edges, edge_index, dim_size = None):\n",
        "\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = 0\n",
        "\n",
        "        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n",
        "\n",
        "        return out, updated_edges\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLu0iKoWCKbF"
      },
      "outputs": [],
      "source": [
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URzZIGyRCKbF"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"num_layers\": 2,\n",
        "    \"hidden_dim\": 64,\n",
        "    \"output_dim\": 1\n",
        "}\n",
        "\n",
        "args = objectview(args)\n",
        "model = MeshGraphNet(1, 3, 64, 1, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFApHjN_CKbF",
        "outputId": "b61e47d5-3eac-4513-a0e7-24ba6a75afa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1796734780073166\n",
            "Model works!\n"
          ]
        }
      ],
      "source": [
        "stats = get_stats(data_list)\n",
        "mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y = stats\n",
        "\n",
        "\n",
        "input_try = data_list[-1]\n",
        "pred = model(input_try, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\n",
        "loss = model.loss(pred, input_try, mean_vec_y, std_vec_y)\n",
        "print(\"Loss:\", loss.item())\n",
        "print(\"Model works!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbsdpjNbCKbF"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNCRym47CKbF"
      },
      "outputs": [],
      "source": [
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nVPRJqbCKbG"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUUU6uELCKbG"
      },
      "outputs": [],
      "source": [
        "def train(dataset, stats_list, args, device=\"cuda\"):\n",
        "\n",
        "    df_train = pd.DataFrame(columns=[\"Epoch\", \"Loss\"])\n",
        "\n",
        "    # Define the model name\n",
        "    model_name = 'model_nl'+str(args.num_layers)+'_bs'+str(args.batch_size) + \\\n",
        "               '_hd'+str(args.hidden_dim)+'_ep'+str(args.epochs)+'_wd'+str(args.weight_decay) + \\\n",
        "               '_lr'+str(args.lr)+'_shuff_'+str(args.shuffle)+'_tr'+str(args.train_size)+'_te'+str(args.test_size)\n",
        "\n",
        "    save_path = os.path.join(model_path, model_name+\".pt\")\n",
        "\n",
        "    # DataLoader\n",
        "    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # The statistics of the data decomposed\n",
        "    [mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y] = stats_list\n",
        "    (mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y) = (mean_vec_x.to(device), std_vec_x.to(device), mean_vec_edge.to(device), std_vec_edge.to(device), mean_vec_y.to(device), std_vec_y.to(device))\n",
        "\n",
        "    # Build model\n",
        "    num_node_features = dataset[0].x.shape[1]\n",
        "    num_edge_features = dataset[0].edge_attr.shape[1]\n",
        "    output_dim = 1\n",
        "\n",
        "    model = MeshGraphNet(num_node_features, num_edge_features, args.hidden_dim, output_dim, args).to(device)\n",
        "    scheduler, optimizer = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # Training\n",
        "    losses = []\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        num_loops = 0\n",
        "        for batch in loader:\n",
        "            optimizer.zero_grad()\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\n",
        "            loss = model.loss(pred, batch, mean_vec_y, std_vec_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            num_loops += 1\n",
        "\n",
        "        total_loss /= num_loops\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} | Loss: {total_loss}\")\n",
        "\n",
        "        df_train.loc[len(df_train)] = [epoch, total_loss]\n",
        "\n",
        "\n",
        "\n",
        "    return model, losses, df_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JZlOI3rFlIz"
      },
      "outputs": [],
      "source": [
        "def test(dataset, stats_list, model, args, device=\"cuda\"):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "  test_losses = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch in test_loader:\n",
        "      batch = batch.to(device)\n",
        "      pred = model(batch, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkDNmn_ACKbG"
      },
      "outputs": [],
      "source": [
        "for args in [\n",
        "        {'model_type': 'meshgraphnet',\n",
        "         'num_layers': 2,\n",
        "         'batch_size': 16,\n",
        "         'hidden_dim': 10,\n",
        "         'epochs': 1000,\n",
        "         'opt': 'adam',\n",
        "         'opt_scheduler': 'none',\n",
        "         'opt_restart': 0,\n",
        "         'weight_decay': 5e-4,\n",
        "         'lr': 0.001,\n",
        "         'train_size': 45,\n",
        "         'test_size': 10,\n",
        "         'device':'cpu',\n",
        "         'shuffle': True,\n",
        "         'save_velo_val': True,\n",
        "         'save_best_model': True,\n",
        "         'checkpoint_dir': './best_models/',\n",
        "         'postprocess_dir': './2d_loss_plots/'},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "\n",
        "torch.manual_seed(5)  #Torch\n",
        "random.seed(5)        #Python\n",
        "np.random.seed(5)     #NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-0FiFT4CKbG"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = torch.load(\"Data/Data4.pt\")\n",
        "\n",
        "stats_list = get_stats(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XjLUqUsFnMQ",
        "outputId": "cda1f1ae-e12d-4d12-c67e-880a1ff8fe05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyDr8KRBCKbG",
        "outputId": "b7d2eb2c-4073-4509-a868-725f80b10bf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 1/1000 [00:07<2:02:35,  7.36s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 0.6417669077505117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 11/1000 [01:20<2:00:48,  7.33s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 0.6215496007302352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 21/1000 [02:34<1:59:06,  7.30s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 | Loss: 0.6215144953863552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 31/1000 [03:47<1:58:37,  7.35s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 | Loss: 0.6215143240672045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 41/1000 [05:01<1:57:48,  7.37s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 | Loss: 0.6215182256045858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▌         | 51/1000 [06:15<1:56:33,  7.37s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 | Loss: 0.6215144961590465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▌         | 61/1000 [07:29<1:55:33,  7.38s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60 | Loss: 0.6215144960238286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   7%|▋         | 71/1000 [08:43<1:54:40,  7.41s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70 | Loss: 0.6215144927400257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 81/1000 [09:57<1:52:45,  7.36s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80 | Loss: 0.6215144789101823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 91/1000 [11:10<1:51:10,  7.34s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90 | Loss: 0.6217362805822586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 101/1000 [12:24<1:50:22,  7.37s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100 | Loss: 0.621514665456997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█         | 111/1000 [13:37<1:49:31,  7.39s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110 | Loss: 0.6215148533676236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 121/1000 [14:51<1:46:54,  7.30s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120 | Loss: 0.6215828378274354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 131/1000 [16:04<1:45:36,  7.29s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 130 | Loss: 0.6215144651803989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▍        | 141/1000 [17:17<1:45:02,  7.34s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 140 | Loss: 0.6215146547913458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▌        | 151/1000 [18:30<1:43:17,  7.30s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 150 | Loss: 0.6215180523410012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▌        | 161/1000 [19:42<1:41:15,  7.24s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160 | Loss: 0.6215136894354965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  17%|█▋        | 171/1000 [20:55<1:41:05,  7.32s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 170 | Loss: 0.6215144457772778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 181/1000 [22:08<1:39:54,  7.32s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 180 | Loss: 0.62198339578805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  19%|█▉        | 191/1000 [23:22<1:39:36,  7.39s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 190 | Loss: 0.6215144781872465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 201/1000 [24:35<1:37:25,  7.32s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200 | Loss: 0.6215144965943061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 211/1000 [25:48<1:35:31,  7.26s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 210 | Loss: 0.6215144856256478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 221/1000 [27:02<1:36:01,  7.40s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 220 | Loss: 0.621524555200749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 231/1000 [28:15<1:33:39,  7.31s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 230 | Loss: 0.6215368925689713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|██▍       | 241/1000 [29:28<1:32:46,  7.33s/Epochs]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 240 | Loss: 0.621514481507421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|██▍       | 245/1000 [29:58<1:32:33,  7.36s/Epochs]"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "model, losses, df_train = train(dataset, stats_list, args, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnym8ll6CKbG"
      },
      "outputs": [],
      "source": [
        "# Plot losses using seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(x=\"Epoch\", y=\"Loss\", data=df_train)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G_8BvUJZkuF"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "model_name = 'model_nl'+str(args.num_layers)+'_bs'+str(args.batch_size) + \\\n",
        "               '_hd'+str(args.hidden_dim)+'_ep'+str(args.epochs)+'_wd'+str(args.weight_decay) + \\\n",
        "               '_lr'+str(args.lr)+'_shuff_'+str(args.shuffle)+'_tr'+str(args.train_size)+'_te'+str(args.test_size)\n",
        "\n",
        "# Save the model\n",
        "# Create the folder\n",
        "os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), os.path.join(args.checkpoint_dir, model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "FBy4wMCXZuhm",
        "outputId": "d841e037-0db7-4cb9-c646-a8bb07057ac2"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8afeaed31ab5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_vec_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_vec_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_vec_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_vec_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_vec_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_vec_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-ed036dd86ac3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Normalize the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_vec_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_vec_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_vec_edge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_vec_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-18ceffb98ff8>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(to_normalize, mean_vec, std_vec)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_normalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_normalize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_unnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_unnormalize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd_vec\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmean_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# Test data\n",
        "test_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "test_losses = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge).to(device)\n",
        "        loss = model.loss(pred, batch, mean_vec_y, std_vec_y)\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "test_loss = np.mean(test_losses)\n",
        "print(f\"Test Loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RTcYpPWaAiM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}