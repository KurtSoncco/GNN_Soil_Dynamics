{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "import enum\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "import torch_scatter\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceleration data\n",
    "df = pd.read_csv(\"Data/Data4.csv\")\n",
    "df.drop(columns=[\"0\"], inplace=True)\n",
    "\n",
    "# Coordinates data\n",
    "df_coord = np.array([[2.5, 5*i] for i in range(0, 31)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data_list\n",
    "data_list = []\n",
    "\n",
    "# Time step\n",
    "dt = 1e-4\n",
    "\n",
    "# Establish some data\n",
    "number_trajectories = 1\n",
    "number_ts = -1\n",
    "\n",
    "# Create file_path\n",
    "data_path = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done collecting data!\n",
      "Data saved!\n",
      "Output Location:  Data\\Data4.pt\n"
     ]
    }
   ],
   "source": [
    "for dt in range(df.shape[0]):\n",
    "    if dt == number_ts:\n",
    "        break\n",
    "\n",
    "    # Get acceleration\n",
    "    acceleration = torch.tensor(df.iloc[dt].values, dtype=torch.float)\n",
    "\n",
    "    # Get edge_index\n",
    "    coordinates = torch.tensor(df_coord, dtype=torch.float)\n",
    "    edges_index = radius_graph(coordinates, r=1.1*5, loop=False).squeeze(0).type(torch.long)\n",
    "\n",
    "    # Get edge_attr\n",
    "    u_i = coordinates[edges_index[0]]\n",
    "    u_j = coordinates[edges_index[1]]\n",
    "    u_ij = u_i - u_j\n",
    "    u_ij_norm = torch.norm(u_ij, p=2, dim=1, keepdim=True)\n",
    "    edge_attr = torch.cat([u_ij, u_ij_norm], dim=-1).type(torch.float)\n",
    "    \n",
    "    # Store data\n",
    "    data_list.append(Data(x=acceleration, edge_index=edges_index, edge_attr=edge_attr, y=acceleration))\n",
    "        \n",
    "print(\"Done collecting data!\")\n",
    "\n",
    "# Save \n",
    "torch.save(data_list, os.path.join(data_path, \"Data4.pt\"))\n",
    "print(\"Data saved!\")\n",
    "print(\"Output Location: \", os.path.join(data_path, \"Data4.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "Normalization is necessary for the features and output parameters to zero mean and unit variance in order to stabilize training. The method defined below, get_stats(), is run before training. It accepts the processed data_list, calculates the mean and standard deviation for the node features, edge features, and node outputs, and normalizes these using the calculated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(to_normalize,mean_vec,std_vec):\n",
    "    return (to_normalize-mean_vec)/std_vec\n",
    "\n",
    "def unnormalize(to_unnormalize,mean_vec,std_vec):\n",
    "    return to_unnormalize*std_vec+mean_vec\n",
    "\n",
    "def get_stats(data_list):\n",
    "    '''\n",
    "    Method for normalizing processed datasets. Given  the processed data_list,\n",
    "    calculates the mean and standard deviation for the node features, edge features,\n",
    "    and node outputs, and normalizes these using the calculated statistics.\n",
    "    '''\n",
    "\n",
    "    # Mean and std of the node features are calculated\n",
    "    mean_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
    "    std_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
    "\n",
    "    # Mean and std of the edge features are calculated\n",
    "    mean_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
    "    std_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
    "\n",
    "    # Mean and std of the output parameters are calculated\n",
    "    mean_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
    "    std_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
    "\n",
    "    # Define the maximum number of accumulations to perform such that we do\n",
    "    # not encounter memory issues\n",
    "    max_accumulations = 10**6\n",
    "\n",
    "    #Define a very small value for normalizing to\n",
    "    eps=torch.tensor(1e-8)\n",
    "\n",
    "    #Define counters used in normalization\n",
    "    num_accs_x = 0\n",
    "    num_accs_edge = 0\n",
    "    num_accs_y = 0\n",
    "\n",
    "    #Iterate through the data in the list to accumulate statistics\n",
    "    for dp in data_list:\n",
    "\n",
    "        # Add to the mean and std vectors for the node features\n",
    "        mean_vec_x+=torch.sum(dp.x,dim=0)\n",
    "        std_vec_x+=torch.sum(dp.x**2,dim=0)\n",
    "        num_accs_x+=dp.x.shape[0]\n",
    "\n",
    "        # Add to the mean and std vectors for the edge features\n",
    "        mean_vec_edge+=torch.sum(dp.edge_attr,dim=0)\n",
    "        std_vec_edge+=torch.sum(dp.edge_attr**2,dim=0)\n",
    "        num_accs_edge+=dp.edge_attr.shape[0]\n",
    "\n",
    "        # Add to the mean and std vectors for the node outputs\n",
    "        mean_vec_y+=torch.sum(dp.y,dim=0)\n",
    "        std_vec_y+=torch.sum(dp.y**2,dim=0)\n",
    "        num_accs_y+=dp.y.shape[0]\n",
    "\n",
    "        if(num_accs_x>max_accumulations or num_accs_edge>max_accumulations or num_accs_y>max_accumulations):\n",
    "            break\n",
    "\n",
    "    mean_vec_x = mean_vec_x/num_accs_x\n",
    "    std_vec_x = torch.maximum(torch.sqrt(std_vec_x/num_accs_x - mean_vec_x**2),eps)\n",
    "\n",
    "    mean_vec_edge = mean_vec_edge/num_accs_edge\n",
    "    std_vec_edge = torch.maximum(torch.sqrt(std_vec_edge/num_accs_edge - mean_vec_edge**2),eps)\n",
    "\n",
    "    mean_vec_y = mean_vec_y/num_accs_y\n",
    "    std_vec_y = torch.maximum(torch.sqrt(std_vec_y/num_accs_y - mean_vec_y**2),eps)\n",
    "\n",
    "    mean_std_list=[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y]\n",
    "\n",
    "    return mean_std_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.node_encoder = Sequential(Linear(input_dim_node , hidden_dim),\n",
    "                                ReLU(),\n",
    "                                Linear( hidden_dim, hidden_dim),\n",
    "                                LayerNorm(hidden_dim))\n",
    "        \n",
    "        self.edge_encoder = Sequential(Linear(input_dim_edge , hidden_dim),\n",
    "                                ReLU(),\n",
    "                                Linear( hidden_dim, hidden_dim),\n",
    "                                LayerNorm(hidden_dim))\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index):\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim_node):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.node_decoder = Sequential(Linear(hidden_dim, hidden_dim),\n",
    "                                ReLU(),\n",
    "                                Linear(hidden_dim, output_dim_node))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.node_decoder(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshGraphNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim, output_dim, args, emb=False):\n",
    "        super(MeshGraphNet, self).__init__()\n",
    "\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(input_dim_node, input_dim_edge, hidden_dim)\n",
    "\n",
    "        # Processor\n",
    "        self.processor = nn.ModuleList()\n",
    "        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n",
    "        \n",
    "        processor_layer=self.build_processor_model()\n",
    "        for _ in range(self.num_layers):\n",
    "            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(hidden_dim, output_dim)\n",
    "\n",
    "    def build_processor_model(self):\n",
    "        return ProcessorLayer\n",
    "\n",
    "    def forward(self,data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge):\n",
    "\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "\n",
    "        # Normalize the input data\n",
    "        x=normalize(x,mean_vec_x,std_vec_x)\n",
    "        edge_attr=normalize(edge_attr,mean_vec_edge,std_vec_edge)\n",
    "\n",
    "        # Encoder\n",
    "        x, edge_attr = self.encoder(x, edge_attr, edge_index)\n",
    "\n",
    "        # Processor\n",
    "        for i in range(self.num_layers):\n",
    "            x, edge_attr = self.processor[i](x, edge_index, edge_attr)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, inputs, mean_vec_y, std_vec_y):\n",
    "\n",
    "        # Normalize the output data\n",
    "        y = inputs.y\n",
    "        y = normalize(y,mean_vec_y,std_vec_y)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = torch.sum((pred-y)**2, axis=1)\n",
    "\n",
    "        # Calculate the sqrt loss\n",
    "        loss = torch.sqrt(loss)\n",
    "\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessorLayer Class: Edge Message Passing, Aggregation, and Updating\n",
    "\n",
    "Now let's implement the processor, which overrides \"[MessagePassing](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html)\" base class. Following the prototype of the base class, we need to implement three main methods, namely message passing, aggregation, and updating. Also, two types of MLP layers, namely node MLP and edge MLP, are defined and used during the construction of processor, whose details will be given in the cell bellow.\n",
    "\n",
    "Essentailly, our processor class serves as the GNN layers composed of message passing, aggregation, and updating, updating information at each layer of the computational graph for each node. The message passing process can be described as:\n",
    "\n",
    "1.   **Message passing**\n",
    "\n",
    "Initiated by the propagate function, the message function most generally calculates messages, m, for edge u at layer l with function MSG given previous embeddings h_u:\n",
    "$$m_u^{(l)}=MSG^{(l)}(h_u^{(l-1)})$$\n",
    "\n",
    "Note that for MeshGraphNets, messages are calculated for edges and passed to nodes. This function thus takes edge embeddings and the adjacent node embeddings and concatenates them. These concatenated previous embeddings constitute h_u above. These are then put through an MLP (our MSG function) to give the final messages, m_u, which are passed to the aggregate function.\n",
    "\n",
    "2.   **Aggregation**\n",
    "\n",
    "Aggregation takes the updated edge embeddings and aggregates then over the connectivity matrix indexing using sum reduction. Most generally, we have:\n",
    "\n",
    "$$h_v^{(l)}=AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})$$\n",
    "\n",
    "For MeshGraphNets, aggregation (AGG) for node v is sum over the neighbor nodes. However, there is also an additional aggregation step: aggregating with the self embedding. This is done outside of the aggregation function, in the forward function after the return of propagate:\n",
    "\n",
    "$$h_v^{(l)}=\\{h_v^{(l-1)},AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})\\}$$\n",
    "\n",
    "3.   **Updating**\n",
    "\n",
    "The nodes embeddings are finally updated by passing $h_v^{(l)}$ through the node MLP with a skip connection. This is most generally written as:\n",
    "\n",
    "$$h_v^{(l)}=Processor(h_v^{(l)})$$\n",
    "\n",
    "Where for us the Processor is an MLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessorLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(ProcessorLayer, self).__init__(**kwargs)\n",
    "\n",
    "        # Note that the node and edge encoders both have the same hidden dimension\n",
    "        # size. This means that the input of the edge processor will always be\n",
    "        # three times the specified hidden dimension\n",
    "        # (input: adjacent node embeddings and self embeddings)\n",
    "        self.edge_mlp = Sequential(Linear( 3* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "        self.node_mlp = Sequential(Linear( 2* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.edge_mlp[0].reset_parameters()\n",
    "        self.edge_mlp[2].reset_parameters()\n",
    "\n",
    "        self.node_mlp[0].reset_parameters()\n",
    "        self.node_mlp[2].reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, size=None):\n",
    "\n",
    "        out, updated_edges = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size) # Out has the shape of [E, out_channels]\n",
    "        updated_nodes = torch.cat([x, out], dim=1) # Complete the aggregation through self-aggregation\n",
    "        updated_nodes = x + self.node_mlp(updated_nodes) # Residual connection\n",
    "\n",
    "        return updated_nodes, updated_edges\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "\n",
    "        updated_edges = torch.cat([x_i, x_j, edge_attr], dim=1) # Shape of [E, 3*in_channels]\n",
    "        updated_edges = self.edge_mlp(updated_edges)\n",
    "\n",
    "        return updated_edges\n",
    "\n",
    "    def aggregate(self, updated_edges, edge_index, dim_size = None):\n",
    "        \n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = 0\n",
    "\n",
    "        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n",
    "\n",
    "        return out, updated_edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"output_dim\": 1\n",
    "}\n",
    "\n",
    "args = objectview(args)\n",
    "model = MeshGraphNet(input_dim_node=1, input_dim_edge=4, hidden_dim=64, output_dim=1, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x31 and 1x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m stats \u001b[38;5;241m=\u001b[39m get_stats(data_list)\n\u001b[0;32m      2\u001b[0m mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y \u001b[38;5;241m=\u001b[39m stats\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_vec_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_vec_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_vec_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_vec_edge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[124], line 33\u001b[0m, in \u001b[0;36mMeshGraphNet.forward\u001b[1;34m(self, data, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\u001b[0m\n\u001b[0;32m     30\u001b[0m edge_attr\u001b[38;5;241m=\u001b[39mnormalize(edge_attr,mean_vec_edge,std_vec_edge)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m x, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Processor\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[122], line 16\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, edge_attr, edge_index)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_attr, edge_index):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, edge_attr\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kurt-\\miniconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x31 and 1x64)"
     ]
    }
   ],
   "source": [
    "stats = get_stats(data_list)\n",
    "mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y = stats\n",
    "\n",
    "model(data_list[0], mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
