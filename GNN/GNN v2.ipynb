{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN based on NHERI AI Academy 2024\n",
    "\n",
    "So, let's use the same architecture used in the previous version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "\n",
    "import torch \n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import torch_cluster\n",
    "import torch_scatter\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import radius_graph\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Case 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(r\"Data\\Data4.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Create a simple MLP\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        layer_sizes,\n",
    "        output_size=None,\n",
    "        output_activation=nn.Identity,\n",
    "        activation=nn.ReLU,\n",
    "        layernorm=True\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        sizes = [input_size] + layer_sizes\n",
    "        if output_size is not None:\n",
    "            sizes.append(output_size)\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            if i < len(sizes) - 2:\n",
    "                if layernorm:\n",
    "                    layers.append(nn.LayerNorm(sizes[i + 1]))\n",
    "                layers.append(activation())\n",
    "            else:\n",
    "                layers.append(output_activation())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_node, in_edge, out_node, out_edge, mlp_num_layers, mlp_hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.node_encoder = MLP(in_node, [mlp_hidden_dim] * mlp_num_layers, out_node)\n",
    "        self.edge_encoder = MLP(in_edge, [mlp_hidden_dim] * mlp_num_layers, out_edge)\n",
    "\n",
    "    def forward(self, x, edge_features):\n",
    "        return self.node_encoder(x), self.edge_encoder(edge_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_node, in_edge, out_node, out_edge, mlp_num_layers, mlp_hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.node_decoder = MLP(in_node, [mlp_hidden_dim] * mlp_num_layers, out_node)\n",
    "        self.edge_decoder = MLP(in_edge, [mlp_hidden_dim] * mlp_num_layers, out_edge)\n",
    "\n",
    "    def forward(self, x, edge_features):\n",
    "        return self.node_decoder(x), self.edge_decoder(edge_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionNetwork(MessagePassing):\n",
    "    def __init__(self, node_fn, edge_fn):\n",
    "        super(InteractionNetwork, self).__init__()\n",
    "        self.node_fn = node_fn\n",
    "        self.edge_fn = edge_fn\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_features=edge_attr)\n",
    "        node_out = self.node_fn(torch.cat([x, aggr], dim=1))\n",
    "        return x + node_out, edge_attr + edge_out\n",
    "\n",
    "    def message(self, xi, xj, edge_features):\n",
    "        return self.edge_fn(torch.cat([xi, xj, edge_features], dim=1))\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        return torch_scatter.scatter(inputs, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor(MessagePassing):\n",
    "    def __init__(self, node_in, node_out, edge_in, edge_out, num_passing_steps, mlp_num_layers, mlp_hidden_dim):\n",
    "        super(Processor, self).__init__()\n",
    "        \n",
    "        self.gnn_stacks = nn.ModuleList([InteractionNetwork(\n",
    "            node_fn = MLP(node_in * 2 + edge_in, [mlp_hidden_dim] * mlp_num_layers, node_out),\n",
    "            edge_fn = MLP(node_in * 2 + edge_in, [mlp_hidden_dim] * mlp_num_layers, edge_out)\n",
    "        )] * num_passing_steps)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for gnn in self.gnn_stacks:\n",
    "            x, edge_attr = gnn(x, edge_index, edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, node_in, node_out, edge_in, edge_out, latent_dim, num_passing_steps, mlp_num_layers, mlp_hidden_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.encoder = Encoder(node_in, edge_in, latent_dim, latent_dim, mlp_num_layers, mlp_hidden_dim)\n",
    "        self.processor = Processor(latent_dim, latent_dim, latent_dim, latent_dim, num_passing_steps, mlp_num_layers, mlp_hidden_dim)\n",
    "        self.decoder = Decoder(latent_dim, latent_dim, node_out, edge_out, mlp_num_layers, mlp_hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x, edge_attr = self.encoder(x, edge_attr)\n",
    "        x, edge_attr = self.processor(x, edge_index, edge_attr)\n",
    "        x, edge_attr = self.decoder(x, edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6]) torch.Size([2, 10]) torch.Size([10, 3]) torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "data = dataset[idx]\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "edge_attr = data.edge_attr\n",
    "y = data.y\n",
    "print(x.shape, edge_index.shape, edge_attr.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_in: int, edge_in: int, \n",
    "                 node_out: int, edge_out: int,\n",
    "                 latent_dim: int, num_passing_steps: int, \n",
    "                 mlp_num_layers: int, mlp_hidden_dim: int, \n",
    "                 connectivity_radius: float):\n",
    "        super(Simulator, self).__init__()\n",
    "        self._connectivity_radius = connectivity_radius\n",
    "        self.GNN = GNN(node_in, node_out, edge_in, edge_out, latent_dim, num_passing_steps, mlp_num_layers, mlp_hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        return self.GNN(x, edge_index, edge_attr)\n",
    "\n",
    "    def create_graph(self, input: torch.Tensor, target: torch.Tensor, coordinates: torch.Tensor):\n",
    "        edge_index = radius_graph(coordinates, r=self._connectivity_radius, loop=False)\n",
    "        \n",
    "        u_i = coordinates[edge_index[0]]\n",
    "        u_j = coordinates[edge_index[1]]\n",
    "        u_ij = u_i - u_j\n",
    "        u_ij_norm = torch.norm(u_ij, p=2, dim=1, keepdim=True)\n",
    "        edge_attr = torch.cat([u_ij, u_ij_norm], dim=-1).float()\n",
    "\n",
    "        return input, edge_index, edge_attr, target\n",
    "\n",
    "    def predict_step(self, input: torch.Tensor, target: torch.Tensor, coordinates: torch.Tensor):\n",
    "        input, edge_index, edge_attr, target = self.create_graph(input, target, coordinates)\n",
    "        output = self.forward(input, edge_index, edge_attr)\n",
    "        return output, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
